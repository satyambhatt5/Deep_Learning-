{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Waste management ",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1cwGBin0r4swgV4YJSodUHrAyI2dZK8Dg",
      "authorship_tag": "ABX9TyODhEuFSWwbTy8LHP+sTsO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyambhatt5/Deep_Learning-/blob/main/Waste_management.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQdCTR74PlZO"
      },
      "source": [
        "#Neural Network with TensorFlow and KERAS\r\n",
        "  \r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "import glob\r\n",
        "import h5py\r\n",
        "import shutil\r\n",
        "import imgaug as aug\r\n",
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import imgaug.augmenters as iaa\r\n",
        "from os import listdir, makedirs, getcwd, remove\r\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\r\n",
        "from pathlib import Path\r\n",
        "from skimage.io import imread\r\n",
        "from skimage.transform import resize\r\n",
        "from keras.models import Sequential, Model, load_model\r\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\r\n",
        "from keras.optimizers import Adam, SGD, RMSprop\r\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\n",
        "from keras.optimizers import Adam, SGD, RMSprop\r\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\r\n",
        "from keras.utils import to_categorical\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from mlxtend.plotting import plot_confusion_matrix\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from mlxtend.plotting import plot_confusion_matrix\r\n",
        "from keras import backend as K\r\n",
        "import tensorflow as tf\r\n",
        " \r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "color = sns.color_palette()\r\n",
        "%matplotlib inline\r\n",
        "%config InlineBackend.figure_format=\"svg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nuHNj3qRhh7"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/Practice Data Set/recycling waste\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znq5tfzeT5MZ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQEwm4a1UndX"
      },
      "source": [
        "idg= ImageDataGenerator(rotation_range=30,rescale=1/255,brightness_range=(0.2,0.5),zoom_range=0.2,shear_range=0.2,horizontal_flip=True)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBBrls3BW6rI"
      },
      "source": [
        "train_gen= idg.flow_from_directory(directory=\"/content/drive/MyDrive/Colab Notebooks/Practice Data Set/recycling waste\",target_size=(224,224),batch_size=128,class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60kPFQkxXwzY"
      },
      "source": [
        "#let create the model here i am going use the vgg16 model \r\n",
        "\r\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efSSi1ccYAIw"
      },
      "source": [
        "#download the model \r\n",
        "\r\n",
        "Vgg16=VGG16(include_top=False,input_shape=(224,224,3),weights=\"imagenet\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-gAOOOVYjKi"
      },
      "source": [
        "# i dont want to make the train the model so the we will remove the model\r\n",
        "\r\n",
        "for layer in Vgg16.layers:\r\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf-ewp0kZM8B"
      },
      "source": [
        "for layer in Vgg16.layers:\r\n",
        "  print(layer.name,layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBr361QnZhBb"
      },
      "source": [
        "#functional way two build the the model API\r\n",
        "\r\n",
        "vgg_output=Vgg16.output\r\n",
        "\r\n",
        "flatten_output=tf.keras.layers.Flatten()(vgg_output)\r\n",
        "\r\n",
        "#first dense layer \r\n",
        "dense1=tf.keras.layers.Dense(256,activation='relu')(flatten_output)\r\n",
        "bn1=tf.keras.layers.BatchNormalization()(dense1)\r\n",
        "dp1=tf.keras.layers.Dropout(0.3)(bn1)\r\n",
        "\r\n",
        "#second dense layer \r\n",
        "dense2=tf.keras.layers.Dense(128,activation='relu')(dp1)\r\n",
        "dp2=tf.keras.layers.Dropout(0.2)(dense2)\r\n",
        "dense3=tf.keras.layers.Dense(units=9,activation='softmax')(dp2)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGIiffaMjyUJ"
      },
      "source": [
        "#del finalModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxqDMXCTaE9d"
      },
      "source": [
        "finalModel=tf.keras.models.Model(inputs=[Vgg16.input],outputs=[dense3])\r\n",
        "finalModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGbcdgrfanlp"
      },
      "source": [
        "finalModel.compile(optimizer=SGD(learning_rate=.01),loss=tf.keras.losses.categorical_crossentropy,metrics=[\"acc\"])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKhCD3VHb8gU"
      },
      "source": [
        "result=finalModel.fit_generator(train_gen,epochs=5,steps_per_epoch=len(train_gen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVIK2AaKeYTy"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\r\n",
        "output_class = [\"batteries\", \"clothes\", \"e-waste\", \"glass\", \"light blubs\", \"metal\", \"organic\", \"paper\", \"plastic\"]\r\n",
        "def waste_prediction(new_image):\r\n",
        "  test_image = image.load_img(new_image, target_size = (224,224))\r\n",
        "  plt.axis(\"off\")\r\n",
        "  plt.imshow(test_image)\r\n",
        "  plt.show()\r\n",
        " \r\n",
        "  test_image = image.img_to_array(test_image) / 255\r\n",
        "  test_image = np.expand_dims(test_image, axis=0)\r\n",
        "\r\n",
        "  predicted_array = model.predict(test_image)\r\n",
        "  predicted_value = output_class[np.argmax(predicted_array)]\r\n",
        "  predicted_accuracy = round(np.max(predicted_array) * 100, 2)\r\n",
        "\r\n",
        "  print(\"Your waste material is \", predicted_value, \" with \", predicted_accuracy, \" % accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}